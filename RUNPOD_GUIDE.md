# üöÄ RunPod Guide –¥–ª—è Mangio RVC

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ü—É–±–ª–∏–∫–∞—Ü–∏—è –æ–±—Ä–∞–∑–∞ –¥–ª—è RunPod

```bash
# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è (CUDA 11.8)
chmod +x build_and_push_runpod.sh
./build_and_push_runpod.sh -u YOUR_DOCKERHUB_USERNAME

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (CUDA 12.1 + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏) ‚ö°
./build_and_push_runpod.sh -u YOUR_DOCKERHUB_USERNAME --optimized
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤ RunPod

1. **–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π Pod** ‚Üí **Custom Template**
2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∏:**
   ```
   Docker Image: YOUR_USERNAME/mangio-rvc-runpod:latest
   Exposed Port: 3000
   GPU: –õ—é–±–∞—è NVIDIA (RTX 3080/4090/A100/H100)
   ```

3. **–ó–∞–ø—É—Å—Ç–∏—Ç—å Pod** –∏ –ø–µ—Ä–µ–π—Ç–∏ –ø–æ –≤—ã–¥–∞–Ω–Ω–æ–º—É URL

## üìã –î–µ—Ç–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### Template Configuration

```yaml
Docker Image: niqr/mangio-rvc-runpod:latest
Container Arguments: 
Exposed Port: 3000
Environment Variables:
  - NVIDIA_VISIBLE_DEVICES=all
  - TZ=UTC
Volume Mapping: 
  - /workspace ‚Üí /app (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
```

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ GPU

| GPU      | VRAM    | –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | –¶–µ–Ω–∞/—á–∞—Å | –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è |
| -------- | ------- | ------------------ | -------- | ------------------ |
| RTX 3080 | 10GB    | –•–æ—Ä–æ—à–æ             | $0.44    | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è        |
| RTX 4090 | 24GB    | –û—Ç–ª–∏—á–Ω–æ            | $0.83    | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è   |
| A100     | 40/80GB | –ú–∞–∫—Å–∏–º—É–º           | $1.89+   | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è   |
| H100     | 80GB    | –£–ª—å—Ç—Ä–∞             | $4.69    | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è   |

### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Pod'–∞

- **CPU**: 8+ —è–¥–µ—Ä
- **RAM**: 16GB+
- **Storage**: 50GB+ (–¥–ª—è –º–æ–¥–µ–ª–µ–π –∏ –¥–∞–Ω–Ω—ã—Ö)
- **Network**: –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å

## üîß –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ
NVIDIA_VISIBLE_DEVICES=all          # –î–æ—Å—Ç—É–ø –∫–æ –≤—Å–µ–º GPU
TZ=UTC                              # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–æ–Ω–∞

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
CUDA_VISIBLE_DEVICES=0              # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ GPU 0
RVC_BATCH_SIZE=32                   # –†–∞–∑–º–µ—Ä batch –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
RVC_MAX_MEMORY=0.9                  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VRAM
```

## üìÅ Volume Mapping

### –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ö–µ–º–∞:
```
/workspace/models ‚Üí /app/pretrained     # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
/workspace/weights ‚Üí /app/weights       # –í–∞—à–∏ –º–æ–¥–µ–ª–∏
/workspace/audio ‚Üí /app/audios          # –í—Ö–æ–¥–Ω—ã–µ –∞—É–¥–∏–æ
/workspace/output ‚Üí /app/audio-outputs  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
/workspace/datasets ‚Üí /app/datasets     # –î–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
```

## üöÄ –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞

–°–æ–∑–¥–∞–π—Ç–µ –≤ `/workspace` —Ñ–∞–π–ª `start_rvc.sh`:

```bash
#!/bin/bash
cd /app

# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
if [ ! -f "hubert_base.pt" ]; then
    echo "Downloading models..."
    ./download_models.sh
fi

# –ó–∞–ø—É—Å–∫ RVC
echo "Starting Mangio RVC..."
python infer-web.py --port 3000 --noautoopen
```

–ò —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É –∑–∞–ø—É—Å–∫–∞:
```bash
Container Arguments: bash /workspace/start_rvc.sh
```

## üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è

### –ß—Ç–æ –≤–∫–ª—é—á–µ–Ω–æ –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é:

- **CUDA 12.1** –≤–º–µ—Å—Ç–æ 11.8 (–¥–æ 30% –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ –Ω–æ–≤—ã—Ö GPU)
- **Multi-stage build** (—Ä–∞–∑–º–µ—Ä –æ–±—Ä–∞–∑–∞ –º–µ–Ω—å—à–µ –Ω–∞ 50%)
- **TensorRT** –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª—è inference
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é GPU
- **Flash Attention** –¥–ª—è A100/H100

### –ó–∞–ø—É—Å–∫ —Å –∞–≤—Ç–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π:

```bash
# –í RunPod Pod'–µ:
python optimize_for_gpu.py

# –ò–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:
docker run -it YOUR_USERNAME/mangio-rvc-runpod:latest python optimize_for_gpu.py && python infer-web.py --port 3000
```

## ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –û–∂–∏–¥–∞–µ–º—ã–µ –≤—Ä–µ–º–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:

| –û–ø–µ—Ä–∞—Ü–∏—è           | RTX 3080 | RTX 4090 | A100     | A100 (–æ–ø—Ç.) |
| ------------------ | -------- | -------- | -------- | ----------- |
| Inference (30s)    | 3-5s     | 2-3s     | 1-2s     | 0.5-1s      |
| Training (1 epoch) | 30-45s   | 20-30s   | 10-15s   | 5-10s       |
| Feature extraction | 2-3 min  | 1-2 min  | 30s-1min | 15-30s      |

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

1. **Batch Size**: –£–≤–µ–ª–∏—á—å—Ç–µ –¥–æ –º–∞–∫—Å–∏–º—É–º–∞ (VRAM)
2. **Mixed Precision**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö GPU
3. **DataLoader Workers**: 4-8 –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö

## üõ†Ô∏è Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: OOM (Out of Memory)
```bash
# –†–µ—à–µ–Ω–∏–µ: –£–º–µ–Ω—å—à–∏—Ç—å batch size
echo "export RVC_BATCH_SIZE=16" >> ~/.bashrc
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
```bash
# –†–µ—à–µ–Ω–∏–µ: –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –≤ –æ–±—Ä–∞–∑
# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —Ç–æ–º
```

### –ü—Ä–æ–±–ª–µ–º–∞: –°–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
curl -I https://huggingface.co/
```

## üí° Pro Tips

1. **Persistent Storage**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Network Volume –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏
2. **Template Sharing**: –°–æ–∑–¥–∞–π—Ç–µ template –∏ –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å –∫–æ–º–∞–Ω–¥–æ–π
3. **Auto-scaling**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Serverless –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
4. **Cost Optimization**: –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ Pod'—ã –∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ

## üìä Monitoring

### –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
```bash
# –í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ Pod'–∞
nvidia-smi -l 1
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤:
```bash
# –õ–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker logs mangio-rvc-runpod -f
```

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [RunPod Documentation](https://docs.runpod.io/)
- [CUDA Compatibility](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/)
- [PyTorch GPU Guide](https://pytorch.org/get-started/locally/)

---

**–ì–æ—Ç–æ–≤–æ!** –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –º–æ—â–Ω–∞—è –æ–±–ª–∞—á–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Mangio RVC! üéµ 